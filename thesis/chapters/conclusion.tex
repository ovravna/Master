% !TEX encoding = UTF-8 Unicode
%!TEX root = ../thesis.tex
% !TEX spellcheck = en-US
%%=========================================
\chapter{Conclusion}




%%=========================================
\section{Limitations}

This project rapport is based on work from a 15 credits course, thus there has been time constraints managing the project with other courses and exams. Combined with the busy schedule of the neuroscientists at the Kavli Institute, it has been challenging to gather feedback in the relatively short time frame of this project.
Of course, the COVID-19 pandemic has made physical sharing of the headset problematic, and thus user testing has been difficult. 
In total, there is a very thin basis for results in this project, but this will hopefully be turned around for the master project.


%%=========================================
\section{Discussion}

% The research question the project set out to answer are


This project has mainly focused on implementing the application answering \href{subrq1}{Sub-RQ1}. As such this can be seen as a minimal viable product for exploring Sub-RQ1, and in that capacity it has shown great promise. The basic tools for dissection is implemented and the medical academics at Kavli Institute and UiO sees great potential in its use. 
As for the Sub-RQ2 and 3, there is less work done. However, by building the application for Android, I have shown that the possibility for cross-platform collaboration is open. And it will be worked on for the master thesis, by implementing networking with \nameref{chap:photon}. Sub-RQ3, has not seen any concrete development, I do have some ideas of how it could be implemented with textures generated from a volumetric brain model. 


%%=========================================
\section{Conclusion}

The state of the project now is a small scale proof of concept for a AR application supporting teaching of neuroanatomy and dissection for medical students. There is still no collaboration or microscopic data visualization in the app. However, the biggest problem with the state of the project is the lack of concrete feedback from medical user groups. It has been received very positively by the neuroscientists who has seen the application in use, and they are awaiting more news on the project. The need for exact user testing and user feedback is still large. The project is however progressing nicely, and with further development I believe this project could create impressing results.


%%=========================================
\section{Further Work}\label{chap:futurework}

% \begin{itemize}
%     \item Collaboration, Networking
%     \item Macro+micro implementation
%     \item Importing new models
%     \item Look into volumetric rendering  
% \end{itemize}

There is still a lot of work left on this project, and it will be continues by me. While there is numerous features and fixes which are waiting in the backlog I would like to focus on the overall picture and what has to be in focus to create an collaborative educational experience in AR. 

\begin{itemize}

    \item {
        \textbf{Focus on usability}\\
        Implement better guidance and affordance such that anyone can use the application. To manage this it will be essential to have user testers and testing with medical user groups. This will give feedback on what makes sense and what doesn't.
        
    }
    \item {
        \textbf{Collaboration; implement cross-platform networking}\\
        Networking tools will be required to create a collaborative experience, this will be done using \nameref{chap:photon} to synchronize the HoloLens 2 application with the Android application.
    }

    \item {
        \textbf{Visualize volumetric data}\\
        While the HoloLens 2 does support volumetric rendering, I am pretty sure it is not in an adequate resolution for this project. It will however be explored. Other than that volumetric data could be used as 2D textures mapped on the clipping plane used to cut the brain.
    }

    \item {
        \textbf{Explore ways of using other brains}\\
        \autoref{chap:elden} explains the steps taken by \citet{Elden2017} to use medical imagery in \nameref{chap:vrvis}. An exploration into whether there is a more elegant way of doing this, should be done.
    }

A general focus when continuing this project should be gathering more user data in the form of user tests and interviews, there should be a focus on establishing whether this project can improve learning outcomes for medical students.


\end{itemize}

\section{Future Work}

% Add newer data set WHS rat brain v4

% Add human brain

% Make app more dynamic => Import brain, labels, infoborad text in runtime

% Improve networking stuff => Microsoft Mesh

% Photon Voice

% Improve Android app => menus with android UI should be possible

% More microscopicaldata Sub RQ3

% Desktop or WebGL view app


This section will lay down suggestions for how to further the project. These are based on the authors experience with the research project and on discussions with the neuro specialists and medical students testing the application.

\subsubsection*{Import new data sets}

As described in \autoref{chap:ratbrain} the WHS rat brain is under continuous development and the the near future there will be released a forth version of the brain model, with improved delineation. It is a high priority wish from the Kavli Institute to use this brain model in the application.

To import a WHS brain model as a geometric model is a complicated process, which has been explained by Elden in \autoref{chap:elden}.
The process of exchanging the geometric model used now with a new one however is trivial, but time consuming. A considerable improvement to the application would be the ability to drop in a new model, preferable at run time such that the application wouldn't need to be build and deploy for each model change.
This would enable future WHS versions to easily be added and even other models like human brains could be switched between.  

Another essential feature to reduce the need for new builds is to enable configuration in-app. The application uses three different text files which saves the configuration of clustering, infoboard and labels, all of these should either be possible to upload at run time or configuration with settings UI in-app.

\subsubsection*{Improve networking}
A critical improvement to the application would be to have the initial scene of the application give the user an option of creating a room, joining an existing room or playing offline.
The application as of now will automatically behind the scene, join the existing room or create one if there is none. This gives users less control but more frictionless when testing collaborative features. In a full scale application the user control would probably be preferable.

The networking solution in the application has a considerable amount of bugs and unexpected behavior, this is probably something that is difficult to completely circumvent, but an effort to restructure or fix this should be done.

%todo Microsoft Mesh?

\subsubsection*{Voice chat}

When collaborating in-app remotely the ability to talk to each other would be a great feature, which for a full scale application would be a high priority. 

\subsubsection*{Platform specific input and UI}
There are few limitations in which platforms the application can run on. However, each platform comes with it's own needs for specific input types and UI. The application has been always been developed with HoloLens 2 as the highest priority and that can be seen in most choices taken conserving UI and input handling. Increasing the user experience on Android and even Windows or WebGL\footnote{The application is buildable for both, but needs input handling to be usable.} should be a priority. Feedback from user testers gave indication that the augmented reality in the android version did not provide an improved user experience and thus disabling camera and spatial features in Android could be seen as an improvement, which could be extended to a desktop application.
A future version of the application running on the web, with WebGL, would probably be possible and further the goal of accessibility.










